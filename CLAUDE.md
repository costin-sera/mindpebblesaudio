# MindPebbles — Voice Journaling with AI Audio Reflection
**Hackathon Product Specification**
_Last updated: 2025-12-11_

MindPebbles is a **lightweight, audio-first journaling web app** designed for rapid introspection.  
Users record short voice entries (“pebbles”), which the system transforms into:

- **Transcription**  
- **Emotional analysis**  
- **Psychological markers**  
- **Key topics**  
- **AI-generated spoken reflections** (via ElevenLabs)

Everything is displayed in a **timeline** of beautifully simple insight cards.

MindPebbles is optimized for **fast hackathon development** using a **frontend-only architecture**, direct API calls, local storage persistence, and minimal dependencies.

---

# 1. Product Overview

MindPebbles helps users drop “mental pebbles” into their day — small, easy voice logs that create ripples of insight.  

**Core Goals:**
- Capture voice quickly  
- Generate emotional + thematic understanding  
- Provide gentle, spoken reflections  
- Visualize entries in a timeline  
- Keep the prototype extremely simple to implement  

---

# 2. Architecture

MindPebbles is built as a **pure frontend web app**.  
No backend is required for the hackathon prototype.

### Why frontend-only?
- Fastest implementation  
- Zero server setup  
- ElevenLabs APIs accept browser requests with API keys  
- LocalStorage is enough for journaling timelines  
- Perfect for localhost demos  

**Tradeoff:**  
API keys will be visible in DevTools — acceptable for hackathons.

---

# 3. Technology Stack

### Frontend
- **React (Vite)** for speed and simplicity
- **MediaRecorder API** for capturing microphone audio
- **CSS modules or Tailwind** for quick styling
- **LocalStorage** for saving entries

### AI + Audio Services
- **ElevenLabs STT (Speech-to-Text)** — transcribe voice notes
- **OpenAI / LLM** — analyze message + extract emotions/topics/psychological markers
- **ElevenLabs TTS (Text-to-Speech)** — generate spoken reflection feedback
- **ElevenLabs Voice Design API** — generate custom AI voices from text descriptions
- **OpenAI GPT-4** — generate custom persona personalities and therapeutic approaches  

---

# 4. User Experience Flow

## 4.1 Home Screen

Displays:

- Big round **Record** button
- Dropdown for selecting **AI Personality** (built-in voices or custom personas)
- Option to **Create New Personality** from the dropdown
- Timeline of past "pebbles" on the right  

## 4.2 Recording Flow

1. User presses **Record**  
2. Browser captures audio using `MediaRecorder`  
3. User presses **Stop**  
4. App calls:
   - ElevenLabs STT → transcript  
   - LLM → insight JSON  
   - ElevenLabs TTS → audio feedback  
5. MindPebbles creates a new **Journal Entry Card** and stores it in `localStorage`.

## 4.3 Reviewing Insights

Each entry shows:

- Emotions (chips or bars)  
- Psychological markers  
- Topics  
- Transcript (collapsible)  
- Summary  
- Original audio  
- AI-generated spoken reflection  

## 4.4 Timeline

Right-side panel listing all entries, newest first.  
Each card contains:

- Timestamp  
- Emotion color or icon  
- Short preview of topics  
- “Play feedback” mini-button  

Clicking a card loads it into the left detail pane.

## 4.5 Custom Personality Creation Flow

1. User selects **"+ Create New Personality"** from the AI Personality dropdown
2. A modal opens with:
   - Description input field for the desired personality
   - Example personality chips (Southern Grandmother, Zen Monk, Life Coach, etc.)
   - Generate button
3. User enters or selects a description and clicks **Generate Personality**
4. System makes two parallel API calls:
   - **OpenAI** generates persona details (name, personality, system prompt, feedback style)
   - **ElevenLabs Voice Design API** generates a custom voice matching the description
5. Preview modal shows:
   - Generated persona name and description
   - Full therapeutic approach/system prompt
   - Feedback style guidelines
   - Audio player to preview the generated voice
6. User can:
   - **Regenerate** to try again with the same or modified prompt
   - **Confirm & Create** to save the persona permanently
7. Once confirmed, the persona is:
   - Saved to localStorage under `mindpebbles_personas`
   - Added to the AI Personality dropdown
   - Automatically selected for the next journal entry

---

# 5. Data Model

## 5.1 Journal Entry

```json
{
  "id": "uuid",
  "createdAt": "2025-12-10T21:34:00Z",
  "transcript": "User's spoken words...",
  "summary": "Short summary of the journal entry...",
  "emotions": [
    { "name": "stress", "score": 0.72 },
    { "name": "hope", "score": 0.41 }
  ],
  "topics": ["work pressure", "self-doubt"],
  "psychMarkers": [
    { "name": "rumination", "level": "high", "description": "..." }
  ],
  "feedbackText": "Spoken reflection generated by AI...",
  "feedbackAudioUrl": "blob:.../ai-feedback.mp3",
  "originalAudioUrl": "blob:.../user-recording.webm",
  "voiceId": "elevenlabs_voice_id"
}
```

Stored in `localStorage` under key:
```
mindpebbles_entries
```

## 5.2 Custom Persona

```json
{
  "id": "uuid",
  "name": "Dr. Sophia",
  "personality": "Warm, empathetic clinical psychologist with gentle wisdom",
  "systemPrompt": "You are Dr. Sophia, a warm and empathetic clinical psychologist...",
  "feedbackStyle": "Provide compassionate, insightful reflections that validate emotions...",
  "voiceId": "elevenlabs_generated_voice_id",
  "createdAt": "2025-12-11T10:15:00Z",
  "isCustom": true
}
```

Stored in `localStorage` under key:
```
mindpebbles_personas
```

---

# 6. Core Functional Specification

## 6.1 Recording Component  
`Recorder.js`

- Start/stop button  
- Uses `navigator.mediaDevices.getUserMedia`  
- Stores audio in Blob format  
- Emits finished audio blob to parent `App.jsx`

## 6.2 STT (Speech-to-Text)  
Called directly via fetch:

```
POST https://api.elevenlabs.io/v1/speech-to-text
Headers: xi-api-key
Body: multipart/form-data (file)
Returns: { text: "transcript" }
```

## 6.3 Insight Analysis (LLM)

Prompt returns structured JSON with:
- summary  
- emotions  
- topics  
- psych_markers  
- feedback_text  

Must be parsed and validated client-side.

## 6.4 TTS (Text-to-Speech)

```
POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}
Headers: xi-api-key
Body: JSON: { text, model_id }
Returns: audio/mpeg
```

Converted into Blob → ObjectURL.

## 6.5 Timeline Component
`Timeline.tsx`

- Displays all stored entries
- Clicking loads the entry into detail view

## 6.6 Custom Persona Generation

**PersonaCreator Component** (`PersonaCreator.tsx`):
- Modal interface for creating custom AI personalities
- Uses OpenAI to generate persona details (name, personality, system prompt, feedback style)
- Uses ElevenLabs Voice Design API to generate matching voice
- Provides preview with audio playback before confirming
- Saves to localStorage under `mindpebbles_personas`

**API Flow**:
1. OpenAI generates persona characteristics from user prompt
2. ElevenLabs creates custom voice preview from personality description
3. User reviews and can regenerate or confirm
4. On confirm, voice is finalized and persona is saved

---

# 7. Insight Card Specification

Each **MindPebble Insight Card** contains:

### 1. Header
- Timestamp  
- Selected voice (icon or name)

### 2. Emotional Profile
- List of `{emotion, score}`  
- Visual style:
  - horizontal bars or color-coded pills  
  - example: Stress ●●●●○ (0.8)

### 3. Topics  
- Chips, e.g.  
  - `work stress`  
  - `identity`  

### 4. Psychological Markers  
Examples:
- rumination (high)  
- self-criticism (medium)  
- avoidance (low)

### 5. Transcript  
Collapsible section with full transcription.

### 6. Summary  
Two-line summary generated by AI.

### 7. Audio Players  
- Original user audio  
- AI feedback audio (ElevenLabs)

---

# 8. LocalStorage Behaviour

### Saving  
Every new entry adds to the array:
```
mindpebbles_entries = JSON.stringify([...entries, newEntry])
```

### Loading  
On app load:
```
const entries = JSON.parse(localStorage.getItem("mindpebbles_entries") || "[]")
```

### Updating  
Timeline renders automatically.

---

# 9. Styling

### Theme: **Calm, pebble-like, soft blues and sand tones**
- Rounded buttons  
- Soft shadows  
- Waveform-inspired graphics  
- Minimalist typography (Inter / Lato)

### Layout:
- Left: Active Entry / Recording  
- Right: Timeline (fixed width ~350px)

---

# 10. Development Setup

### Install

```
npm create vite@latest mindpebbles --template react
cd mindpebbles
npm install
npm run dev
```

### Environment Variables  
Stored in `.env` (visible to FE in hackathon):

```
ELEVENLABS_API_KEY=...
OPENAI_API_KEY=...
```

Access via `import.meta.env`.

---

# 11. Limitations (Acceptable for Hackathon)

- API keys exposed  
- No server-side audio storage  
- No user accounts  
- Limited privacy (localhost only)  
- No pagination or advanced search  

---

# 12. Recent Updates

## Custom Personality Creation (Added 2025-12-11)

Users can now create fully custom AI personalities with unique voices directly from the app:

**Key Features**:
- Describe desired personality in natural language
- AI generates complete therapeutic persona (name, approach, style)
- Custom voice automatically generated to match personality
- Preview persona and voice before saving
- Personas persist in localStorage and appear in personality selector
- Built-in example suggestions (Southern Grandmother, Zen Monk, Life Coach, etc.)

**Technical Implementation**:
- New `Persona` data type in [src/types/index.ts](src/types/index.ts)
- `PersonaCreator` UI component with modal interface
- Three new API functions:
  - `generatePersonaFromPrompt()` - OpenAI persona generation
  - `generateVoiceFromPrompt()` - ElevenLabs voice preview
  - `createVoiceFromPreview()` - Finalize voice
- Integration with existing voice selection system
- Custom personas stored alongside built-in voices

---

# 13. Future Enhancements (Post-hackathon)

- Secure backend to hide keys
- Advanced emotion timeline graph
- Word clouds from topics
- "Compare me over time" insights
- Daily prompts
- Pebble streaks
- Export as audio "memory reel"
- Persona editing and deletion
- Share custom personas with others

---

# 14. Summary

**MindPebbles** is a lightweight personal voice journal where emotional insights surface automatically and AI speaks back with comforting, human-like reflections.

Optimized for:
- **Speed of development**  
- **Audio-first interaction**  
- **Immediate emotional value**  
- **Hackathon demonstration appeal**

